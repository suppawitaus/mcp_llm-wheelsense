# MCP Smart Environment System - Environment Configuration
# Copy this file to .env and modify as needed

# ========== LLM Configuration ==========
# Ollama service URL (use service name in Docker, localhost for local development)
OLLAMA_HOST=http://ollama:11434

# LLM model name (default: qwen2.5:7b)
# Alternative models: deepseek-r1:latest, llama3.2:3b, etc.
MODEL_NAME=qwen2.5:7b

# ========== Database Configuration ==========
# SQLite database path (relative to project root)
DATABASE_PATH=data/smart_environment.db

# Database backup directory
DATABASE_BACKUP_DIR=data/backups

# Enable SQL query logging (for debugging)
# Set to "true" to see all database queries in console
ENABLE_DATABASE_LOGGING=false

# ========== Prompt Configuration ==========
# Use compact system prompts (reduces token usage, may affect LLM behavior)
# Set to "true" to use compact prompts
USE_COMPACT_PROMPT=false

# ========== Streamlit Configuration ==========
# Streamlit server port
STREAMLIT_SERVER_PORT=8501

# Streamlit server address (0.0.0.0 for all interfaces, 127.0.0.1 for localhost only)
STREAMLIT_SERVER_ADDRESS=0.0.0.0
